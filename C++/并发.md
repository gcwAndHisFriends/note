```c++
#include<thread>
#include<iostream>
using namespace std;

void hello(){
	cout<<"hello"<<endl;
}

int main(){
    std::thread t(hello);
    t.join();
}
```

每个线程都必须具有一个初始函数(initial function)，新线程的执行从这里开始，这里时hello作为初始

新的线程启动之后，初始线程继续执行如果它不等待新线程结束，它就将自顾自地继续运 行到main()的结束，从而结束程序。

join则会让t结束后，main才会继续运行

std::thread 可以用可调用类型构造，将带有函数调用符类型的实例传 入 std::thread 类中，替换默认的构造函数

```c++
class background_task
{
    public:
    void operator()() const //重载括号运算符?
    {
        do_something();
        do_something_else();
    }
};
background_task f;
std::thread my_thread(f);
```

函数调用运算符 () 可以被重载用于类的对象。当重载 () 时，您不是创造了一种新的调用函数的方式，相反地，这是创建一个可以传递任意数目参数的运算符函数。

```c++
#include <iostream>
using namespace std;
 
class Distance
{
   private:
      int feet;             // 0 到无穷
      int inches;           // 0 到 12
   public:
      // 所需的构造函数
      Distance(){
         feet = 0;
         inches = 0;
      }
      Distance(int f, int i){
         feet = f;
         inches = i;
      }
      // 重载函数调用运算符
      Distance operator()(int a, int b, int c)
      {
         Distance D;
         // 进行随机计算
         D.feet = a + c + 10;
         D.inches = b + c + 100 ;
         return D;
      }
      // 显示距离的方法
      void displayDistance()
      {
         cout << "F: " << feet <<  " I:" <<  inches << endl;
      }
      
};
int main()
{
   Distance D1(11, 10), D2;

   cout << "First Distance : "; 
   D1.displayDistance();

   D2 = D1(10, 10, 10); // invoke operator()
   cout << "Second Distance :"; 
   D2.displayDistance();

   return 0;
}
```

当上面的代码被编译和执行时，它会产生下列结果：

```c++
First Distance : F: 11 I:10
Second Distance :F: 30 I:120
```

当把函数对象传入到线程构造函数中时，需要避免“最令人头痛的语法解 析.如果你传递了一个临时变量，而不是一个命名的变 量；C++编译器会将其解析为**函数声明，而不是类型对象的定义**。 例如： 

```c++
std::thread my_thread(background_task());
```

这里相当与声明了一个名为my_thread的函数，这个函数带有一个参数(函数指针指向没有参 数并返回background_task对象的函数)，返回一个 std::thread 对象的函数，而非启动了一个 线程。

使用在前面命名函数对象的方式，或使用多组括号①，或使用新统一的初始化语法②，可以避 免这个问题。 如下所示： 

```c++
std::thread my_thread((background_task())); // 1 
std::thread my_thread{background_task()}; // 2
```

启动了线程，你需要明确是要等待线程结束，还是让其自主运行。

如果 std::thread 对象销毁之前还没有做出决定，程序就会终止 。因此，即便是有异常存在，也需要确保线程能够正确的加入(joined)或分离(detached)。必须在 std::thread 对象销毁之前做出决定，否则你的程序将会终止 ( std::thread 的析构函数会调用 std::terminate() ，这时再去决定会触发相应异常)。

```c++
struct func
{
    int& i;
    func(int& i_) : i(i_) {}
    void operator() ()
    {
    	for (unsigned j=0 ; j<1000000 ; ++j)
    {
    	do_something(i); // 1 潜在访问隐患：悬空引用
    }
    }
};
void oops()
{
    int some_local_state=0;
    func my_func(some_local_state);
    std::thread my_thread(my_func);
    my_thread.detach(); // 2 不等待线程结束
} // 3 新线程可能还在运行

```

当oops()函数执行完成时 ③，新线程中的函数可能还在运行。如果线程还在运行，它就会去调用do_something(i)函数 ①，这时就会访问已经销毁的变量。

处理这种情况的常规方法：使线程函数的功能齐全，将数据复制到线程中，而非复制到共享 数据中。如果使用一个可调用的对象作为线程函数，这个对象就会复制到线程中，而后原始 对象就会立即销毁。

如果打算等待对应线程，则需要细心 挑选调用join()的位置。当在线程运行之后产生异常，在join()调用之前抛出，就意味着这次调 用会被跳过。

避免应用被抛出的异常所终止，就需要作出一个决定。通常，当倾向于在无异常的情况下使 用join()时，需要在异常处理过程中调用join()，从而避免生命周期的问题。下面的程序清单是 一个例子。

```c++
struct func; // 定义在清单2.1中
void f()
{
    int some_local_state=0;
    func my_func(some_local_state);
    std::thread t(my_func);
    try
    {
    	do_something_in_current_thread();
    }
    catch(...)
    {
        t.join(); // 1
        throw;
    }
    t.join(); // 2
}
```

当函数 正常退出时，会执行到②处；当函数执行过程中抛出异常，程序会执行到①处。

一种方式是使用“资源获取即初始化方式

```c++
class thread_guard
{
    std::thread& t;
    public:
        explicit thread_guard(std::thread& t_):
        	t(t_)
        {}
        ~thread_guard()
        {
            if(t.joinable()) // 1
            {
            	t.join(); // 2
            }
        }
        thread_guard(thread_guard const&)=delete; // 3
        thread_guard& operator=(thread_guard const&)=delete;
};
struct func; // 定义在清单2.1中
void f()
{
int some_local_state=0;
func my_func(some_local_state);
std::thread t(my_func);
thread_guard g(t);
do_something_in_current_thread();
} // 4
```

当线程执行到④处时，局部对象就要被逆序销毁了。因此，thread_guard对象g是第一个被销 毁的，这时线程在析构函数中被加入②到原始线程中。即使do_something_in_current_thread 抛出一个异常，这个销毁依旧会发生。

在thread_guard的析构函数的测试中，首先判断线程是否已加入①，如果没有会调用join()② 进行加入。这很重要，因为join()只能对给定的对象调用一次，所以对给已加入的线程再次进 行加入操作时，将会导致错误。

拷贝构造函数和拷贝赋值操作被标记为 =delete ③，是为了不让编译器自动生成它们。直接 对一个对象进行拷贝或赋值是危险的，因为这可能会弄丢已经加入的线程。通过删除声明， 任何尝试给thread_guard对象赋值的操作都会引发一个编译错误。



使用detach()会让线程在后台运行，这就意味着主线程不能与之产生直接交互。

## 2.2 向线程函数传递参数

```c++
void f(int i, std::string const& s);
std::thread t(f, 3, "hello");
```

代码创建了一个调用f(3, "hello")的线程。注意，函数f需要一个 std::string 对象作为第二个 参数，但这里使用的是字符串的字面值，也就是 char const * 类型。之后，在线程的上下文 中完成字面值向 std::string 对象的转化。需要特别要注意，当指向动态变量的指针作为参数 传递给线程的情况，代码如下：

```c++
void f(int i,std::string const& s);
void oops(int some_param)
{
    char buffer[1024]; // 1
    sprintf(buffer, "%i",some_param);
    std::thread t(f,3,buffer); // 2
    t.detach();
}
```

这种情况下，buffer①是一个指针变量，指向本地变量，然后本地变量通过buffer传递到新线 程中②。并且，函数有很有可能会在字面值转化成 std::string 对象之前崩溃(oops)，想要依赖隐式转换将字面值转换为函数期待的 std::string 对象,从而导 致一些未定义的行为。std::thread 的构造函数会**复制**提供的变量，就只复制了没有转换成期望类型的字符串字 面值。解决方案就是在传递到 std::thread 构造函数之前就将字面值转化为 std::string 对象



还可能遇到相反的情况：期望传递一个**非常量引用**(但这不会被编译)，但整个对象被复制了。 你可能会尝试使用线程更新一个引用传递的数据结构，比如：

```c++
void update_data_for_widget(widget_id w,widget_data& data); // 1
void oops_again(widget_id w)
{
    widget_data data;
    std::thread t(update_data_for_widget,w,data); // 2
    display_status();
    t.join();
    process_widget_data(data);
}
```

虽然update_data_for_widget①的第二个参数期待传入一个引用，但是 std::thread 的构造函 数②并不知晓；构造函数无视函数期待的参数类型，**并盲目的拷贝已提供的变量**。

可以使用 std::ref 将参数转换成引用的形式，从而可将线程的调用改为以下形式：

```c++
std::thread t(update_data_for_widget,w,std::ref(data));
```

在这之后，update_data_for_widget就会接收到一个data变量的引用，而非一个data变量拷贝 的引用，这样代码就能顺利的通过编译。



可以传递一个成员函数指针作为线程函数， 并提供一个合适的对象指针作为第一个参数：

```c++
class X
{
    public:
    void do_lengthy_work();
};
X my_x;
std::thread t(&X::do_lengthy_work,&my_x); // 1
```

这段代码中，新线程将my_x.do_lengthy_work()作为线程函数；my_x的地址①作为指针对象 提供给函数。也可以为成员函数提供参数： std::thread 构造函数的第三个参数就是成员函数 的第一个参数，以此类推(代码如下，译者自加)。

```c++
class X
{
    public:
    void do_lengthy_work(int);
};
X my_x;
int num(0);
std::thread t(&X::do_lengthy_work, &my_x, num);
```

提供的参数可以移动，但不能拷贝。"移动"是指:原始对象中的数据转移给另一对 象，而转移的这些数据就不再在原始对象中保存了。当原对象是一个临时变量时，自动进行移动操作， 但当原对象是一个命名变量，那么转移的时候就需要使用 std::move() 进行显示移动。下面的 代码展示了 std::move 的用法，展示了 std::move 是如何转移一个动态对象到一个线程中去 的：

```c++
void process_big_object(std::unique_ptr<big_object>);

std::unique_ptr<big_object> p(new big_object);
p->prepare_data(42);
std::thread t(process_big_object,std::move(p));
```

## 2.3 转移线程所有权

假设要写一个在后台启动线程的函数，并想通过新线程返回的所有权去调用这个函数，而不 是等待线程结束再去调用；或完全与之相反的想法：创建一个线程，并在函数中转移所有 权，都必须要等待线程结束。所以，新线程的所有权都需要转移。

C++标准库中有很多资源占有类型，比如 std::ifstream ， std::unique_ptr 还有 std::thread 都是可移动，但不可拷贝。这就说明执行线程的所有权可以在 std::thread 实例中移动

下面将展示一个例子。例子中， 创建了两个执行线程，并且在 std::thread 实例之间(t1,t2和t3)转移所有权：

```c++
void some_function();
void some_other_function();
std::thread t1(some_function); // 1
std::thread t2=std::move(t1); // 2
t1=std::thread(some_other_function); // 3
std::thread t3; // 4
t3=std::move(t2); // 5
t1=std::move(t3); // 6 赋值操作将使程序崩溃

```

新线程开始与t1相关联①。当显式使用 std::move() 创建t2后②，t1的所有权就转移给 了t2。

之后，t1和执行线程已经没有关联了，执行some_function的函数线程与t2关联。

一个临时 std::thread 对象相关的线程启动了③。为什么不显式调用 std::move() 转移 所有权呢？因为，所有者是一个临时对象——移动操作将会隐式的调用。

t3使用默认构造方式创建④，与任何执行线程都没有关联。调用 std::move() 将与t2关联线程 的所有权转移到t3中⑤。因为t2是一个命名对象，需要显式的调用 std::move() 。

移动操作 #5 完成后，t1与执行some_other_function的线程相关联，t2与任何线程都无关联，t3与执行 some_function的线程相关联。

最后一个移动操作，将some_function线程的所有权转移⑥给t1。不过，t1已经有了一个关联 的线程(执行some_other_function的线程)，所以这里系统直接调用 std::terminate() 终止程 序继续运行。这样做（不抛出异常， std::terminate() 是noexcept函数)是为了保证 与 std::thread 的析构函数的行为一致。

std::thread 支持移动，就意味着线程的所有权可以在函数外进行转移，就如下面程序一样。

```c++
std::thread f()
{
    void some_function();
    return std::thread(some_function);
}
std::thread g()
{
    void some_other_function(int);
    std::thread t(some_other_function,42);
    return t;
}
```

当所有权可以在函数内部传递，就允许 std::thread 实例可作为参数进行传递，代码如下：

```c++
void f(std::thread t);
void g()
{
    void some_function();
    f(std::thread(some_function));
    std::thread t(some_function);
    f(std::move(t));
}

```

当某个对象转移了线程的所有权后，它就不能对线程进行加入或分离。 为了确保线程程序退出前完成，下面的代码里定义了scoped_thread类

```c++
class scoped_thread
{
    std::thread t;
public:
    explicit scoped_thread(std::thread t_): // 1
    t(std::move(t_))
    {
        if(!t.joinable()) // 2
        	throw std::logic_error(“No thread”);
    }
    ~scoped_thread()
    {
    t.join(); // 3
    }
    scoped_thread(scoped_thread const&)=delete;
    scoped_thread& operator=(scoped_thread const&)=delete;
};
struct func; // 定义在清单2.1中
void f()
{
    int some_local_state;
    scoped_thread t(std::thread(func(some_local_state))); // 4
    do_something_in_current_thread();
}                                                         //5
```

explicit关键字:指定构造函数或转换函数 (C++11起)为显式, 即它不能用于隐式转换和复制初始化.

构造函数后的冒号是一种初始化形式

```c++
class Clock{
public:
private:
  int hour, minute, second;
};

Clock::Clock (int newH, int newM, int newS) :hour (newH), minute (newM), second (newS) {}
```

新线程直接传递到scoped_thread中④，而非创建一个独立变量。当主线 程到达f()函数末尾时⑤，scoped_thread对象就会销毁，然后加入③到的构造函数①创建的线 程对象中去。

noexcept: 指定某个函数是否可能会引发异常。无条件版本相当于 `noexcept(true)`当 noexcept 是 true 时表示函数不会抛出异常,

```c++
class joining_thread
{
	std::thread t;
public:
    joining_thread() noexcept=default; //通过=default来将该函数声明为默认构造函数
    
    //模板 Callable传入函数, ...args缺省
    template<typename Callable,typename ... Args>
    explicit joining_thread(Callable&& func,Args&& ... args)://使用函数名与参数构造
    	t(std::forward<Callable>(func),std::forward<Args>(args)...)
    {}
    /*
    std::forward通常是用于完美转发的，它会将输入的参数原封不动地传递到下一个函数中
    “原封不动”指的是，如果输入的参数是左值，那么传递给下一个函数的参数的也是左值；如果输入的参数是右值，那	么传递给下一个函数的参数的也是右值。
    int a; // a 为左值
	a = 3; // 3 为右值
	左值是可寻址的变量，有持久性；
	右值一般是不可寻址的常量，或在表达式求值过程中创建的无名临时对象，短暂性的
	左值和右值主要的区别之一是左值可以被修改，而右值不能。
	左值引用：引用一个对象；
	右值引用：就是必须绑定到右值的引用，C++11中右值引用可以实现“移动语义”，通过 && 获得右值引用。
	int x = 6; // x是左值，6是右值
    int &y = x; // 左值引用，y引用x
    
    int &z1 = x * 6; // 错误，x*6是一个右值
    const int &z2 =  x * 6; // 正确，可以将一个const引用绑定到一个右值

    int &&z3 = x * 6; // 正确，右值引用
    int &&z4 = x; // 错误，x是一个左值
    
    右值引用和相关的移动语义是C++11标准中引入的最强大的特性之一，通过std::move()可以避免无谓的复制，提高程序性能。
    */
    explicit joining_thread(std::thread t_) noexcept://使用另一个线程构造
    	t(std::move(t_))
    {}
    joining_thread(joining_thread&& other) noexcept://使用另一个joining_thread参数构造
    	t(std::move(other.t))                       //并且这个参数是右值引用的
    {}
    
    joining_thread& operator=(joining_thread&& other) noexcept //被赋值
    {
        if（joinable()）{//先完成自己的线程
        	join();
    	}
        t = std::move(other.t);//再接受别人的线程
        return *this;
    }
    joining_thread& operator=(std::thread other) noexcept
    {
        if(joinable())
        	join();
        t=std::move(other);
        return *this;
    }
    ~joining_thread() noexcept
    {
        if(joinable())
        join();
    }
    void swap(joining_thread& other) noexcept
    {
    	t.swap(other.t);
    }
    std::thread::id get_id() const noexcept{
    	return t.get_id();
    }
    bool joinable() const noexcept
    {
    	return t.joinable();
    }
    void join()
    {
    	t.join();
    }
    void detach()
    {
    	t.detach();
    }
    std::thread& as_thread() noexcept
    {
    	return t;
    }
    const std::thread& as_thread() const noexcept
    {
    	return t;
    }
};
```

std::thread 对象的容器，如果这个容器是移动敏感的(比如，标准中的 std::vector<> )，那 么移动操作同样适用于这些容器。了解这些后，就可以写出类似清单2.7中的代码，代码量产 了一些线程，并且等待它们结束。 清单2.8 量产线程，等待它们结束

```c++
void do_work(unsigned id);
void f()
{
    std::vector<std::thread> threads;
    for(unsigned i=0; i < 20; ++i)
    {
    	threads.push_back(std::thread(do_work,i)); // 产生线程
    }
    /*
    函数模板std :: mem_fn生成指向成员的指针的包装对象，该对象可以存储，复制和调用指向成员的指针。 调用std :: mem_fn时，可以使用对象的引用和指针（包括智能指针）。
    */
    std::for_each(threads.begin(),threads.end(),
    std::mem_fn(&std::thread::join)); // 对每个线程调用join()

}

```



# 线程之间共享数据

## 3.2.1 C++中使用互斥量

C++中通过实例化 std::mutex 创建互斥量实例，通过成员函数lock()对互斥量上锁，unlock() 进行解锁。。不过，实践中不推荐直接去调用成员函数，调用成员函数就意味着，必须在每个 函数出口都要去调用unlock()，也包括异常的情况。C++标准库为互斥量提供了一个RAII语法 的模板类 std::lock_guard ，在构造时就能提供已锁的互斥量，并在析构的时候进行解锁，从 而**保证了一个已锁互斥量能被正确解锁**。

```c++
#include <list>
#include <mutex>
#include <algorithm>
std::list<int> some_list; // 1
std::mutex some_mutex; // 2
void add_to_list(int new_value)
{
    std::lock_guard<std::mutex> guard(some_mutex); // 3
    some_list.push_back(new_value);
}
bool list_contains(int value_to_find)
{
    std::lock_guard<std::mutex> guard(some_mutex); // 4
    return std::find(some_list.begin(),some_list.end(),value_to_find) !=some_list.end();
}
```

清单3.1中有一个全局变量①，这个全局变量被一个全局的互斥量保护②。add_to_list()③和 list_contains()④函数中使用 std::lock_guard ，使得这两个函数中对数据的访问 是互斥的：list_contains()不可能看到正在被add_to_list()修改的列表。

C++17中添加了一个新特性，称为模板类参数推导，这样类似 std::locak_guard 这样简单的 模板类型的模板参数列表可以省略。③和④的代码可以简化成：

```c++
std::lock_guard guard(some_mutex);
```

在大多数情况下，互斥量通常会与需要保护的数据放在 同一类中，而不是定义成全局变量。互斥量和需要保护的数据，在类中都定义为 private成员，这会让访问数据的代码更清晰，并且容易看出在什么时候对互斥量上锁。当所 有成员函数都会在调用时对数据上锁，结束时对数据解锁，这就保证了访问时数据不变量不 被破坏。



当其中一个成员函数返回的是保 护数据的指针或引用时，会破坏数据。具有访问能力的指针或引用可以访问(并可能修改)被保 护的数据，而不会被互斥锁限制。这就需要对接口有相当谨慎的设计，要确保互斥量能锁住 数据的访问，并且不留后门。

## 3.2.2 用代码来保护共享数据

切勿将受保护数据的指针或引用传递到互斥锁作用域之外，无论是 函数返回值，还是存储在外部可见内存，亦或是以参数的形式传递到用户提供的函数中去。

## 定义线程安全的堆栈

清单3.4中是一个接口没有条件竞争的堆栈类定义，它实现了选项1和选项3：重载了pop()，使 用一个局部引用去存储弹出值，并返回一个 std::shared_ptr<> 对象。它有一个简单的接口， 只有两个函数：push()和pop();

```c++
#include <exception>
#include <memory> // For std::shared_ptr<>
struct empty_stack: std::exception //标准异常类的基类
{
	const char* what() const throw();
};
template<typename T>
class threadsafe_stack
{
    public:
    threadsafe_stack();
    threadsafe_stack(const threadsafe_stack&);
    threadsafe_stack& operator=(const threadsafe_stack&) = delete;
    // 1 赋值操作被删除
    void push(T new_value);
    std::shared_ptr<T> pop();
    void pop(T& value);
    bool empty() const;
};
```

```c++
#include <exception>
#include <memory>
#include <mutex>
#include <stack>
struct empty_stack: std::exception
{
    const char* what() const throw() {
    	return "empty stack!";
	};
};
template<typename T>
class threadsafe_stack{
private:
	std::stack<T> data;
	mutable std::mutex m;
public:
    threadsafe_stack()
    	: data(std::stack<T>()){}//通过一个stack来构造
    threadsafe_stack(const threadsafe_stack& other)
    {
        std::lock_guard<std::mutex> lock(other.m);
        data = other.data; // 1 在构造函数体中的执行拷贝
    }
    threadsafe_stack& operator=(const threadsafe_stack&) = delete;
    void push(T new_value){
        std::lock_guard<std::mutex> lock(m);
        data.push(new_value);
    }
    std::shared_ptr<T> pop()//返回智能指针
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack(); // 在调用pop前，检查栈是否
        为空
        std::shared_ptr<T> const res(std::make_shared<T>
        (data.top())); // 在修改堆栈前，分配出返回值
        data.pop();
        return res;
    }
    void pop(T& value)//返回引用
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack();
        value=data.top();
        data.pop();
    }
    bool empty() const{
        std::lock_guard<std::mutex> lock(m);
        return data.empty();
    }
};
```

## 避免死锁

C++标准库有办法解决这个问题， std::lock ——可以一次性锁住多个(两个以上)的 互斥量，并且没有副作用(死锁风险)。下面的程序清单中，就来看一下怎么在一个简单的交换操作中使用 std::lock 。

```c++
// 这里的std::lock()需要包含<mutex>头文件
class some_big_object;
void swap(some_big_object& lhs,some_big_object& rhs);
class X
{
private:
    some_big_object some_detail;
    std::mutex m;
public:
    X(some_big_object const& sd):some_detail(sd){}
    friend void swap(X& lhs, X& rhs)
    {
        if(&lhs==&rhs)
        	return;
        std::lock(lhs.m,rhs.m); // 1
        std::lock_guard<std::mutex> lock_a(lhs.m,std::adopt_lock);
        // 2
        std::lock_guard<std::mutex> lock_b(rhs.m,std::adopt_lock);
        // 3
        swap(lhs.some_detail,rhs.some_detail);
    }
};
```

调用 std::lock() ①锁住 两个互斥量，并且两个 std:lock_guard 实例已经创建好②③

提供 std::adopt_lock 参数除了 表示 std::lock_guard 对象可获取锁之外，还将锁交由 std::lock_guard 对象管理，而不需 要 std::lock_guard 对象再去构建新的锁。

这样，就能保证在大多数情况下，函数退出时互斥量能被正确的解锁(保护操作可能会抛出一 个异常)，也允许使用一个简单的“return”作为返回。还有，当使用 std::lock 去锁lhs.m或 rhs.m时，可能会抛出异常；这种情况下，异常会传播到 std::lock 之外。当 std::lock 成功 的获取一个互斥量上的锁，并且当其尝试从另一个互斥量上再获取锁时，就会有异常抛出， 第一个锁也会随着异常的产生而自动释放，所以 std::lock 要么将两个锁都锁住，要不一个 都不锁。

C++17对这种情况提供了支持， std::scoped_lock<> 一种新的RAII类型模板类型， 与 std::lock_guard<> 的功能等价，这个新类型能接受不定数量的互斥量类型作为模板参数， 以及相应的互斥量(数量和类型)作为构造参数。互斥量支持构造即上锁，与 std::lock 的用法 相同，其解锁阶段是在析构中进行。清单3.6中swap()操作可以重写如下：

```c++
void swap(X& lhs, X& rhs)
{
    if(&lhs==&rhs)
    return;
    std::scoped_lock guard(lhs.m,rhs.m); // 1 这里使用了C++17的另一个特性：自动推导模板参数。
    swap(lhs.some_detail,rhs.some_detail);
}
```

## 3.2.7 不同域中互斥量所有权的传递

std::unique_lock 实例没有与自身相关的互斥量，一个互斥量的所有权可以通过移动操作， 在不同的实例中进行传递。std::unique_lock 是可移 动，但不可赋值的类型

一种使用可能是允许一个函数去锁住一个互斥量，并且将所有权移到调用者上，所以调用者 可以在这个锁保护的范围内执行额外的动作。

下面的程序片段展示了：函数get_lock()锁住了互斥量，然后准备数据，返回锁的调用函数。

```c++
std::unique_lock<std::mutex> get_lock()
{
    extern std::mutex some_mutex;
    std::unique_lock<std::mutex> lk(some_mutex);
    prepare_data();
    return lk; // 1
}
void process_data()
{
    std::unique_lock<std::mutex> lk(get_lock()); // 2
    do_something();
}

```

lk在函数中被声明为自动变量，它不需要调用 std::move() ，可以直接返回①(编译器负责调用 移动构造函数)。process_data()函数直接转移 std::unique_lock 实例的所有权②，调用 do_something()可使用的正确数据(数据没有受到其他线程的修改)。

std::unique_lock 的灵活性同样也允许实例在销毁之前放弃其拥有的锁。可以使用unlock()来 做这件事，如同一个互斥量： std::unique_lock 的成员函数提供类似于锁定和解锁互斥量的 功能。 std::unique_lock 实例在销毁前释放锁的能力，当锁没有必要在持有的时候，可以在 特定的代码分支对其进行选择性的释放。

## 3.2.8 锁的粒度

3.2.3节中，已经对锁的粒度有所了解：锁的粒度是一个摆手术语(hand-waving term)，用来描 述通过一个锁保护着的数据量大小。

## 3.3.1 保护共享数据的初始化过程

清单 3.11 使用一个互斥量的延迟初始化(线程安全)过程

```c++
std::shared_ptr<some_resource> resource_ptr;
std::mutex resource_mutex;
void foo()
{
    std::unique_lock<std::mutex> lk(resource_mutex); // 所有线程在此序列化
    if(!resource_ptr)
    {
    	resource_ptr.reset(new some_resource); // 只有初始化过程需要保护
    }
    lk.unlock();
    resource_ptr->do_something();
}
```

这段代码相当常见了，也足够表现出没必要的线程化问题，

比起锁住互斥量并显式的检查指针， 每个线程只需要使用 std::call_once 就可以，在 std::call_once 的结束时，就能安全的知道 指针已经被其他的线程初始化了。

使用 std::call_once 比显式使用互斥量消耗的资源更少， 特别是当初始化完成后。下面的例子展示了与清单3.11中的同样的操作，这里使用 了 std::call_once 。在这种情况下，初始化通过调用函数完成，这样的操作使用类中的函数 操作符来实现同样很简单。如同大多数在标准库中的函数一样，或作为函数被调用，或作为 参数被传递， std::call_once 可以和任何函数或可调用对象一起使用。

```c++
std::shared_ptr<some_resource> resource_ptr;
std::once_flag resource_flag; // 1
void init_resource()
{
    resource_ptr.reset(new some_resource);
}
void foo()
{
    std::call_once(resource_flag,init_resource); // 可以完整的进行一次初始化
    resource_ptr->do_something();
}
```

清单3.12 使用 std::call_once 作为类成员的延迟初始化(线程安全)

```c++
class X
{
private:
    connection_info connection_details;
    connection_handle connection;
    std::once_flag connection_init_flag;
    
    void open_connection()
    {
        connection=connection_manager.open(connection_details);
    }
public:
    X(connection_info const& connection_details_):
    connection_details(connection_details_)
    {}
    void send_data(data_packet const& data) // 1
    {
    	std::call_once(connection_init_flag,&X::open_connection,this);
    	// 2
    	connection.send_data(data);
    }
    data_packet receive_data() // 3
    {
        std::call_once(connection_init_flag,&X::open_connection,this);
        // 2
        return connection.receive_data();
	}
};

```

## 3.3.2 保护不常更新的数据结构

这样的更新要求线程独占数据结构的访问权，直到其完成更新操 作。当更新完成，数据结构对于并发多线程访问又会是安全的。使用 std::mutex 来保护数据 结构，显的有些反应过度(因为在没有发生修改时，它将削减并发读取数据的可能性)。

这种互斥量常被称为“读者-作者锁”，因为其允许两种不同的使用方 式：一个“作者”线程独占访问和共享访问，让多个“读者”线程并发访问。

C++17标准库提供了两种非常好的互斥量 —— std::shared_mutex 和 std::shared_timed_mutex 。C++14只提供 了 std::shared_timed_mutex ，并且在C++11中并未提供任何互斥量类型。如果你还在用支持 C++14标准之前的编译器，那你可以使用Boost库中实现的互斥 量。 std::shared_mutex 和 std::shared_timed_mutex 的不同点在 于， std::shared_timed_mutex 支持更多的操作方式(参考4.3节)， std::shared_mutex 有更高的 性能优势，从而不支持更多的操作。

比起使用 std::mutex 实例进行同步，不如使用 std::shared_mutex 来做同步。对于更新操作， 可以使用 std::lock_guard 和 std::unique_lock 上锁。

当任一线程拥有一个共享锁时，这个线程就会尝试获取一个独占锁，直到其他线程放弃他们的锁；同样的，当任一线程拥有一个独占锁时，其他线程就无法 获得共享锁或独占锁，直到第一个线程放弃其拥有的锁。

下面的代码清单展示了一个简单的DNS缓存，使用 std::map 持有缓存 数据，使用 std::shared_mutex 进行保护。

```c++
#include <map>
#include <string>
#include <mutex>
#include <shared_mutex>
class dns_entry;
class dns_cache
{
    std::map<std::string,dns_entry> entries;
    mutable std::shared_mutex entry_mutex;
public:
    dns_entry find_entry(std::string const& domain) const//读取
    {
        std::shared_lock<std::shared_mutex> lk(entry_mutex); // 1
        std::map<std::string,dns_entry>::const_iterator const it=entries.find(domain);
        return (it==entries.end())?dns_entry():it->second;
    }
    void update_or_add_entry(std::string const& domain,dns_entry const& dns_details)//更新
    {
        std::lock_guard<std::shared_mutex> lk(entry_mutex); // 2
        entries[domain]=dns_details;
    }
};
```

find_entry()使用 std::shared_lock<> 来保护共享和只读权限①；这就使得多线程 可以同时调用find_entry()，且不会出错。另一方面，update_or_add_entry()使用 std::lock_guard<> 实例，当表格需要更新时②，为其提供独占访问权限；

update_or_add_entry()函数调用时，独占锁会阻止其他线程对数据结构进行修改，并且阻止 线程调用find_entry()。

## 3.3.3 嵌套锁

当一个线程已经获取一个 std::mutex 时(已经上锁)，并对其再次上锁，这个操作就是错误 的，并且继续尝试这样做的话，就会产生未定义行为。然而，在某些情况下，一个线程尝试 获取同一个互斥量多次，而没有对其进行一次释放是可以的。之所以可以，是因为C++标准库 提供了 std::recursive_mutex 类。除了可以对同一线程的单个实例上获取多个锁，其他功能与 std::mutex 相同。互斥量锁住其他线程前，必须释放拥有的所有锁，所以当调用lock()三次 后，也必须调用unlock()三次。正确使 用 std::lock_guard 和 std::unique_lock 可以帮 你处理这些问题。

# 第4章 同步并发操作

我们不仅想要保护数据，还想对单 独的线程进行同步。例如，在第一个线程完成前，可能需要等待另一个线程执行完成。通常 情况下，线程会等待一个特定事件发生，或者等待某一条件达成。这可能需要定期检查“任务 完成”标识，或将类似的东西放到共享数据中，但这与理想情况差很多。像这种情况就需要在 线程中进行同步，C++标准库提供了一些工具可用于同步操作，形式上表现为条件变量 (condition variables)和期望值(futures)。并发技术规范(TS)中，为期望值添加了更多的操作， 并与新的同步工具锁存器(latches)(轻量级锁资源)和栅栏机制(barriers)一起使用。

使用C++标准库提供的工具去等待事件的发生。通过另一线 程触发等待事件的机制是最基本的唤醒方式(例如：流水线上存在额外的任务时)，这种机制就 称为“条件变量”。从概念上来说，一个条件变量会与多个事件或其他条件相关，并且一个或多 个线程会等待条件的达成。当某些线程被终止时，为了唤醒等待线程(允许等待线程继续执 行)，终止线程将会向等待着的线程广播“条件达成”的信息。

## 4.1.1 等待条件达成

C++标准库对条件变量有两套实 现： std::condition_variable 和 std::condition_variable_any 。

两者都需要与一个互斥量一起才能工作(互斥量是 为了同步)；前者仅限于与 std::mutex 一起工作，而后者可以和任何满足最低标准的互斥量一 起工作，从而加上了_any的后缀。因为 std::condition_variable_any 更加通用，这就可能从 体积、性能，以及系统资源的使用方面产生额外的开销，所以 std::condition_variable 一般 作为首选的类型，当对灵活性有硬性要求时，我们才会去考虑 std::condition_variable_any 。

清单4.1 使用 std::condition_variable 处理数据等待

```c++
std::mutex mut;
std::queue<data_chunk> data_queue; // 1
std::condition_variable data_cond;
void data_preparation_thread()
{
    while(more_data_to_prepare())
    {
        data_chunk const data=prepare_data();
        std::lock_guard<std::mutex> lk(mut);
        data_queue.push(data); // 2
        data_cond.notify_one(); // 3
    }
}
void data_processing_thread()
{
    while(true)
    {
        std::unique_lock<std::mutex> lk(mut); // 4
        data_cond.wait(lk,[]{return !data_queue.empty();}); // 5
        data_chunk data=data_queue.front();
        data_queue.pop();
        lk.unlock(); // 6
        process(data);
        if(is_last_chunk(data))
        	break;
    }
}
```

首先，有一个用来在两个线程之间传递数据的队列①。当数据准备好时，使 用 std::lock_guard 对队列上锁,将准备好的数据压入队列中②，之后线程会对队列中的数据 上锁。再调用 std::condition_variable 的notify_one()成员函数，对等待的线程(如果有等待线 程)进行通知③。

另外一侧，有一个正在处理数据的线程，这个线程首先对互斥量上锁，但这 里 std::unique_lock 要比 std::lock_guard ④更加合适。线程之后会调 用 std::condition_variable 的成员函数wait()，传递一个锁和一个lambda函数表达式(作为等 待的条件⑤)。

如果条件不满足(lambda函数返回false)，wait()函数将解锁互斥量，并且将这个线程 (上段提到的处理数据的线程)置于阻塞或等待状态。

当准备数据的线程调用notify_one()通知 条件变量时，处理数据的线程从睡眠状态中苏醒，重新获取互斥锁，并且再次检查条件是否 满足。在条件满足的情况下，从wait()返回并继续持有锁；当条件不满足时，线程将对互斥量 解锁，并且重新开始等待。这就是为什么用 std::unique_lock 而不使用 std::lock_guard —— 等待中的线程必须在等待期间解锁互斥量，并在这之后对互斥量再次上锁，而 std::lock_guard 没有这么灵活。如果互斥量在线程休眠期间保持锁住状态，准备数据的线 程将无法锁住互斥量，也无法添加数据到队列中；同样的，等待线程也永远不会知道条件何 时满足。

本质上说， std::condition_variable::wait 是对“忙碌-等待”的一种优化。的确，不理想的方式 就是用简单的循环来实现：

## 4.1.2 使用条件变量构建线程安全队列

```c++
#include <memory> // 为了使用std::shared_ptr
template<typename T>
class threadsafe_queue
{
public:
    threadsafe_queue();
    threadsafe_queue(const threadsafe_queue&);
    threadsafe_queue& operator=(const threadsafe_queue&) = delete; // 不允许简单的赋值
    void push(T new_value);
    bool try_pop(T& value); // 1
    std::shared_ptr<T> try_pop(); // 2
    void wait_and_pop(T& value);
    std::shared_ptr<T> wait_and_pop();
    bool empty() const;
};
```

第一个重载的try_pop()①在引用变量中存储着 检索值，所以它可以用来返回队列中值的状态；当检索到一个变量时，他将返回true，否则将 返回false(详见A.2节)。第二个重载②就不能做这样了，因为它是用来直接返回检索值的。当 没有值可检索时，这个函数可以返回NULL指针。

```c++
#include <queue>
#include <mutex>
#include <condition_variable>
template<typename T>
class threadsafe_queue
{
private:
    std::mutex mut;
    std::queue<T> data_queue;
    std::condition_variable data_cond;
public:
    void push(T new_value)
    {
        std::lock_guard<std::mutex> lk(mut);
        data_queue.push(new_value);
        data_cond.notify_one();
    }
    void wait_and_pop(T& value)
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk,[this]{return !data_queue.empty();});
        value=data_queue.front();
        data_queue.pop();
    }
};
threadsafe_queue<data_chunk> data_queue; // 1
void data_preparation_thread()
{
    while(more_data_to_prepare())
    {
        data_chunk const data=prepare_data();
        data_queue.push(data); // 2
    }
}
void data_processing_thread()
{
    while(true)
    {
        data_chunk data;
        data_queue.wait_and_pop(data); // 3
        process(data);
        if(is_last_chunk(data))
            break;
    }
}
```

线程队列的实例中包含有互斥量和条件变量，所以独立的变量就不需要了①，并且调用push() 也不需要外部同步②。当然，wait_and_pop()还要兼顾条件变量的等待③。 另一个wait_and_pop()函数的重载写起来就很琐碎了，剩下的函数就像从清单3.5实现的栈中 一个个的粘过来一样。最终的队列实现如下所示。

```c++
#include <queue>
#include <memory>
#include <mutex>
#include <condition_variable>
template<typename T>
class threadsafe_queue
{
private:
    mutable std::mutex mut; // 1 互斥量必须是可变的 被mutable修饰的变量，将永远处于可变的状态，即使在一个const函数中
    std::queue<T> data_queue;
    std::condition_variable data_cond;
public:
    threadsafe_queue()
    {}
    threadsafe_queue(threadsafe_queue const& other)
    {
        std::lock_guard<std::mutex> lk(other.mut);
        data_queue=other.data_queue;
    }
    void push(T new_value)
    {
        std::lock_guard<std::mutex> lk(mut);
        data_queue.push(new_value);
        data_cond.notify_one();
    }
    void wait_and_pop(T& value)
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk,[this]{return !data_queue.empty();});
        value=data_queue.front();
        data_queue.pop();
    }
    std::shared_ptr<T> wait_and_pop()
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk,[this]{return !data_queue.empty();});
        std::shared_ptr<T> res(std::make_shared<T>
        (data_queue.front()));
        data_queue.pop();
        return res;
    }
    bool try_pop(T& value)
    {
        std::lock_guard<std::mutex> lk(mut);
        if(data_queue.empty())
        return false;
        value=data_queue.front();
        data_queue.pop();
        return true;
    }
    std::shared_ptr<T> try_pop()
    {
        std::lock_guard<std::mutex> lk(mut);
        if(data_queue.empty())
        return std::shared_ptr<T>();
        std::shared_ptr<T> res(std::make_shared<T>
        (data_queue.front()));
        data_queue.pop();
        return res;
    }
    bool empty() const
    {
        std::lock_guard<std::mutex> lk(mut);
        return data_queue.empty();
    }
};
```

## 4.2 使用期望值等待一次性事件

当线程需要等待特定的一次性事件 时，某种程度上来说就需要知道这个事件在未来的期望结果。之后，这个线程会周期性(较短 的周期)的等待或检查，事件是否触发(检查信息板)；检查期间也会执行其他任务

另外，等待任务期间它可以先执行另外一些任务，直到对应的任务触发，而后等待期 望值的状态会变为就绪(ready)。

一个期望值可能是数据相关的(比如，你的登机口编号)，也可 能不是。当事件发生时(并且期望状态为就绪)，并且这个期望值就不能被重置。

C++标准库中，有两种期望值，使用两种类型模板实现，声明在  头文件中: 唯一期望 值(unique futures)( std::future<> )和共享期望值(shared futures)( std::shared_future<> )。 仿照了 std::unique_ptr 和 std::shared_ptr 。

std::future 的实例只能与一个指定事件相关 联，而 std::shared_future 的实例就能关联多个事件。后者的实现中，所有实例会在同时变 为就绪状态，并且他们可以访问与事件相关的任何数据。

## 4.2.1 后台任务的返回值

因 为 std::thread 并不提供直接接收返回值的机制。这里就需要 std::async 函数模板

当不着急要任务结果时，可以使用 std::async 启动一个异步任务。与 std::thread 对象等待 的方式不同， std::async 会返回一个 std::future 对象，这个对象持有最终计算出来的结 果。当需要这个值时，只需要调用这个对象的get()成员函数；并且会**阻塞线程**直到期望值状 态为就绪为止；之后，返回计算结果。下面清单中代码就是一个简单的例子。

```c++
#include <future>
#include <iostream>
int find_the_answer_to_ltuae();
void do_other_stuff();
int main()
{
    std::future<int>the_answer=std::async(find_the_answer_to_ltuae);
    do_other_stuff();
    std::cout<<"The answer is "<<the_answer.get()<<std::endl;
}
```

与 std::thread 做的方式一样， std::async 允许你通过添加额外的调用参数，向函数传递额 外的参数。当第一个参数是一个指向成员函数的指针，第二个参数提供有这个函数成员类的 具体对象(不是直接的，就是通过指针，还可以包装在 std::ref 中)，剩余的参数可作为成员 函数的参数传入。

否则，第二个和随后的参数将作为函数的参数，或作为指定可调用对象的 第一个参数。就如 std::thread ，当参数为右值时，拷贝操作将使用移动的方式转移原始数 据。这就允许使用“只移动”类型作为函数对象和参数。

```c++
#include <string>
#include <future>
struct X
{
    void foo(int,std::string const&);
    std::string bar(std::string const&);
};
X x;
auto f1=std::async(&X::foo,&x,42,"hello"); // 调用p->foo(42,"hello")，p是指向x的指针
auto f2=std::async(&X::bar,x,"goodbye"); // 调用tmpx.bar("goodbye")， tmpx是x的拷贝副本
struct Y
{
	double operator()(double);
};
Y y;
auto f3=std::async(Y(),3.141); // 调用tmpy(3.141)，tmpy通过Y的移动构造函数得到
auto f4=std::async(std::ref(y),2.718); // 调用y(2.718)
//std::ref 
X baz(X&);
std::async(baz,std::ref(x)); // 调用baz(x)
class move_only
{
public:
    move_only();
    move_only(move_only&&)
    move_only(move_only const&) = delete;
    move_only& operator=(move_only&&);
    move_only& operator=(move_only const&) = delete;
    void operator()();
};
auto f5=std::async(move_only()); // 调用tmp()，tmp是通过std::move(move_only())构造得到
```

默认情况下，期望值是否等待取决于 std::async 是否启动一个线程，或是否有任务正在进行 同步。大多数情况下(估计这就是你想要的结果)，也可以在函数调用之前向 std::async 传递 一个额外参数，这个参数的类型是 std::launch ，还可以是 std::launch::defered ，表明函数 4.2 使用期望等待一次性事件 110 调用被延迟到wait()或get()函数调用时才执行(惰性)， std::launch::async 表明函数必须在其所在的 独立线程上执行， std::launch::deferred | std::launch::async 表明实现可以选择这两种方式 的一种。最后一个选项是默认的，当函数调用被延迟，它可能不会在运行了。如下所示：

```c++
auto f6=std::async(std::launch::async,Y(),1.2); // 在新线程上执行
auto f7=std::async(std::launch::deferred,baz,std::ref(x)); // 在wait()或get()调用时执行
auto f8=std::async(std::launch::deferred | std::launch::async,baz,std::ref(x)); // 实现选择执行方式
auto f9=std::async(baz,std::ref(x));
f7.wait(); // 调用延迟函数
```

## 4.2.2 任务与期望值关联

使用 std::async 会更容易让算法分割到各 个任务中，这样程序就能并发的执行了。不过，这不是让 std::future 与任务实例相关联的唯 一方式；你也可以将任务包装入 std::packaged_task<> 实例中，或通过编写代码的方式，使 用 std::promise<> 类型模板显示设置值。与 std::promise<> 对比， std::packaged_task<> 具 有更高层的抽象，所以我们从“高抽象”的模板说起。

std::packaged_task<> 对一个函数或可调用对象，绑定一个期望值。当调用 std::packaged_task<> 对象时，它就会调用相关函数或可调用对象，将期望状态置为就绪，返回值也会被存储。

std::packaged_task<> 的模板参数是一个函数签名，比如void()就是一个**没有参数也没有返回值**的函数，或int(std::string&, double*)就是有一个非const引用的 std::string 和一个指向 double类型的指针，并且返回类型是int。

当构造出一个 std::packaged_task<> 实例时，就必须 传入一个**函数或可调用对象**；

这个函数或可调用的对象，需要能接收指定的参数和返回可转换为指定返回类型的值。

类型可以不完全匹配，可以用一个int类型的参数和返回一个float类 型的函数，来构建 std::packaged_task 的实例，因为这里类型可以隐式转 换。

函数签名的返回类型可以用来标识从get_future()返回的 std::future<> 的类型，而函数签名的 参数列表，可用来指定packaged_task的函数调用操作符。例如，模板**偏特化** std::packaged_task*,int)> 将在下面的代码清单中使用。(只支持一部分)

```c++
template<>
class packaged_task<std::string(std::vector<char>*,int)>
{
public:
    template<typename Callable>
    explicit packaged_task(Callable&& f);//不能用于隐式转换和复制初始化.
    std::future<std::string> get_future();
    void operator()(std::vector<char>*,int);
};
```

因为 std::packaged_task 对象是一个可调用对象，所以可以封装在 std::function 对象中,从 而作为线程函数传递到 std::thread 对象中
当 std::packaged_task 作为一个函数被调用时，实参将由函数调用操作符传递 到底层函数，并且返回值作为异步结果存储在 std::future ，可通过get_future()获取。

线程间传递任务

很多图形架构需要特定的线程去更新界面，所以当一个线程对界面的更新时，它要发出一条 信息给正确的线程，让特定的线程来做界面更新。 std::packaged_task 提供了实现这种功能 的方法，且不需要发送一条自定义信息给图形界面相关线程。下面来看看代码。

```c++
#include <deque>
#include <mutex>
#include <future>
#include <thread>
#include <utility>
std::mutex m;
std::deque<std::packaged_task<void()> > tasks;
bool gui_shutdown_message_received();
void get_and_process_gui_message();
void gui_thread() // 1
{
    while(!gui_shutdown_message_received()) // 2
    {
        get_and_process_gui_message(); // 3
        std::packaged_task<void()> task;
    	{
            std::lock_guard<std::mutex> lk(m);
            if(tasks.empty()) // 4
                continue;
            task=std::move(tasks.front()); // 5
            tasks.pop_front();
   		}
    	task(); // 6
   	}
}
std::thread gui_bg_thread(gui_thread);
template<typename Func>
std::future<void> post_task_for_gui_thread(Func f)
{
    std::packaged_task<void()> task(f); // 7
    std::future<void> res=task.get_future(); // 8
    std::lock_guard<std::mutex> lk(m);
    tasks.push_back(std::move(task)); // 9
    return res; // 10
}
```

图形界面线程①循环直到收到一条关闭图形界面的信息后关闭②进行轮 询界面消息处理③，用户点击和执行在队列中的任务。当队列中没有任务④，它将再次 循环；除非，它能在队列中提取出一个任务⑤，然后释放队列上的锁，并且执行任务⑥。这 里，期望值与任务相关，当任务执行完成时，其状态会被置为“就绪”状态。

将一个任务传入队列：提供的函数⑦可以提供一个打包好的任务,可以通过这个任务⑧调用 get_future()成员函数获取期望值对象,并且在任务被推入列表⑨之前，期望值将返回调用函 数⑩。当需要知道线程执行完任务时，向图形界面线程发布消息的代码，会等待期望值改变状 态；否则，会丢弃这个期望值。

例子中使用 std::packaged_task 创建任务，其包含了一个无参数无返回值的函数或可 调用对象(如果当这个调用有返回值时，返回值会被丢弃)。

## 4.2.3 使用(std::)promises

当一个应用需要处理很多网络连接时，它会使用不同线程尝试连接每个接口，因为这能使网 络尽早联通，尽早执行程序。当连接较少的时候，工作没有问题(也就是线程数量比较少)。不 幸的是，随着连接数量的增长，这种方式变的越来越不合适；因为大量的线程会消耗大量的 系统资源，还有可能造成线程上下文频繁切换(当线程数量超出硬件可接受的并发数时)，这都 会对性能有影响。最极端的例子：系统资源被创建的线程消耗殆尽，系统连接网络的能力会 变的极差。**因此通过少数线程(可能只有一个)处理网络连接，每个线程同时处理多个连接事 件，对需要处理大量的网络连接的应用而言是普遍的做法。**

std::promise 提供设定值的方式(类型为T)，这个类型会和后面看到的 std::future 对 象相关联。一对 std::promise/std::future 会为这种方式提供一个可行的机制；期望值可以阻 塞等待线程，同时，提供数据的线程可以使用组合中的承诺值来对相关值进行设置，并将期 望值的状态置为“就绪”。

可以通过一个给定的 std::promise 的get_future()成员函数来获取与之相关的 std::future 对 象，跟 std::packaged_task 的用法类似。当承诺值已经设置完毕(使用set_value()成员函数)， 对应期望值的状态变为“就绪”，并且可用于检索已存储的值。当在设置值之前销 毁 std::promise ，将会存储一个异常。在4.2.4节中，会详细描述异常是如何传送到线程的。 清单4.10中，单线程处理多接口的实现，如同之前所说，在这个例子中，可以使用一 对 std::promise/std::future 找出一块传出成功的数据块；与期望值相关的只是 一个简单的“成功/失败”标识。对于传入包，与期望值相关的数据就是数据包的有效负载。 清单4.10 使用承诺值解决单线程多连接问题

```c++
#include <future>
void process_connections(connection_set& connections)
{
    while(!done(connections)) // 1
    {
        // 2
        for(connection_iterator connection=connections.begin(),end=connections.end();connection!=end;++connection)
        {
            if(connection->has_incoming_data()) // 3
            {
                data_packet data=connection->incoming();
                std::promise<payload_type>& p=connection->get_promise(data.id); // 4
                p.set_value(data.payload);
            }
            if(connection->has_outgoing_data()) // 5
            {
                outgoing_packet data=
                connection->top_of_outgoing_queue();
                connection->send(data.payload);
                data.promise.set_value(true); // 6
            }
        }
    }
}
```

函数process_connections()中，直到done()返回true①为止

。每一次循环，都会依次的检查每 一个连接②，

检索是否有数据③或正在发送已入队的传出数据⑤

假设输入数据包是具有ID和 有效负载的(有实际的数在其中)。一个ID映射到一个 std::promise (可能是在相关容器中进行 的依次查找)④并且值是设置在包的有效负载中的。

对于传出包，包是从传出队列中进行检 索的，实际上从接口直接发送出去。当发送完成，与传出数据相关的承诺值将置为true，来表 明传输成功⑥。

是否能映射到实际网络协议上，取决于网络所用协议；这里的“承诺值/期望 值”组合方式可能在特殊的情况下无法工作，但它与一些操作系统支持的异步输入/输出结构类 似。

## 4.3 限定等待时间

两种指定超时方式：一种是“时延”，另一种是“绝对时间点”。第一种方式，需要指定一段 时间(例如，30毫秒)；第二种方式，就是指定一个时间点(例如，世界标准时间 [UTC]17:30:15.045987023，2011年11月30日)。

多数等待函数提供变量，对两种超时方式进 行处理。处理持续时间的变量以\_for作为后缀，处理绝对时间的变量以\_until作为后缀。

## 4.3.1 时钟

对于C++标准库来说，时钟就是时间信息源。并且，时钟是一个类，提供了四种不同的信息： 

当前时间

 时间类型 

时钟节拍 

通过时钟节拍的分布，判断时钟是否稳定 

当前时间可以通过调用静态成员函数now()从时钟类中获取，例 如， std::chrono::system_clock::now() 是将返回系统时钟的当前时间。

特定的时间点类型可 以通过time_point的数据typedef成员来指定，所以some_clock::now()的类型就是 some_clock::time_point。

时钟节拍被指定为1/x(x在不同硬件上有不同的值)秒，这是由时间周期所决定——一个时钟一 秒有25个节拍，因此一个周期为 std::ratio<1, 25> ，当一个时钟的时钟节拍每2.5秒一次， 周期就可以表示为 std::ratio<5, 2> 。

当时钟节拍均匀分布(无论是否与周期匹配)，并且不可调整，这种时钟就称为稳定时钟。当 is_steady静态数据成员为true时，表明这个时钟就是稳定的；否则，就是不稳定的。

通常情 况下， std::chrono::system_clock 是不稳定的，因为时钟是可调的，即是这种是完全自动适 应本地账户的调节。这种调节可能造成的是，首次调用now()返回的时间要早于上次调用 now()所返回的时间，这就违反了节拍频率的均匀分布。

稳定闹钟对于超时的计算很重要，所 以C++标准库提供一个稳定时钟 std::chrono::steady_clock 。C++标准库提供的其他时钟可表 示为 std::chrono::system_clock (在上面已经提到过)，它代表了系统时钟的“实际时间”，并且 提供了函数可将时间点转化为time_t类型的值； std::chrono::high_resolution_clock 可能是 标准库中提供的具有最小节拍周期(因此具有最高的精度[分辨率])的时钟。它实际上是typedef 的另一种时钟，这些时钟和其他与时间相关的工具，都被定义在  库头文件中。

## 4.3.2 时延

时间部分最简单的就是时延， std::chrono::duration<> 函数模板能够对时延进行处理。(线程库 使用到的所有C++时间处理工具，都在 std::chrono 命名空间内)第一个模板参数是一个类 型表示(比如，int，long或double)，第二个模板参数是定制部分，表示每一个单元所用秒数。

例如，当几分钟的时间要存在short类型中时，可以写成 std::chrono::duration<short,std::ratio<60, 1>> ，因为60秒是才是1分钟，所以第二个参数写成 std::ratio<60, 1> 。当需 要将毫秒级计数存在double类型中时，可以写成 std::chrono::durationn<double, std::ratio<1，1000>> ，因为1秒等于1000毫秒。

方便起见，C++14中 std::chrono_literals 命名空间中，有许多预定义的后缀操作符用来表示 时长。下面简单的代码就是使用硬编码的方式赋予具体的时长值：

```c++
using namespace std::chrono_literals;
auto one_day=24h;
auto half_an_hour=30min;
auto max_time_between_messages=30ms;
```

当使用整型字面符，这些后缀类似使用了预定义的类型，比如：15ns 和 std::chrono::nanoseconds(15) 就是等价的。不过，当使用浮点字面量时，且未指明表示类 型时，数值上会对浮点时长进行适当的缩放。

因此，2.5min会被表示 为 std::chrono::duration\<some-floating-point-type,std::ratio<60,1>> 

当不要求截断值的情况下(时转换成秒是没问题，但是秒转换成时就不行)时延的转换是隐式 的。显示转换可以由 std::chrono::duration_cast<> 来完成

```c++
std::chrono::milliseconds ms(54802);
std::chrono::seconds s=std::chrono::duration_cast<std::chrono::seconds>(ms);
```

这里的结果就是截断的，而不是进行了舍入，所以s最后的值为54。

延迟支持四则运算，如，5*seconds(1)与seconds(5)或 minutes(1)-seconds(55)

在时延中可以通过count()成员函数获得单位时间的数量。例 如， std::chrono::milliseconds(1234).count() 就是1234

基于时延的等待可由 std::chrono::duration<> 来完成，例如：等待期望值状态变为就绪已经 35毫秒：

```c++
std::future<int> f=std::async(some_task);
if(f.wait_for(std::chrono::milliseconds(35))==std::future_status::ready)
	do_something_with(f.get());
```

等待函数会返回一个状态值，表示是等待是超时，还是继续等待。

这里可以等待期望值，所 以当函数等待超时时，会返回 std::future_status::timeout

当期望值状态改变，函数会返 回 std::future_status::ready

当与期望值相关的任务延迟了，函数会返 回 std::future_status::deferred

基于时延的等待是使用内部库的稳定时钟来计时的；所 以，即使系统时钟在等待时被调整(向前或向后)，35毫秒的时延在这里意味着，的确耗时35毫 秒。

当然，系统调度的不确定性和不同操作系统的时钟精度都意味着：线程调用和返回的实 际时间间隔可能要比35毫秒长。

## 4.3.3 时间点

时间点可以用 std::chrono::time_point<> 类型模板来表示，实例的第一个参数用来指定所要 使用的时钟，第二个函数参数用来表示时间的计量单位

一 个时间点的值就是时间的长度(在指定时间的倍数内)，例如，指定“unix时间戳”(epoch)为一个 时间点。时间戳是时钟的一个基本属性，但是不可以直接查询，或在C++标准中已经指定。

通 常，unix时间戳表示1970年1月1日 00:00，即计算机启动应用程序时。时钟可能共享一个时 间戳，或具有独立的时间戳。当两个时钟共享一个时间戳时，其中一个time_point类型可以与 另一个时钟类型中的time_point相关联。

通过对 指定time_point类型使用time_since_epoch()来获取时间戳，该成员函数会返回一个时延值， 这个时延值是指定时间点与unix时间戳的时间间隔。

你可以通过 std::chrono::time_point<> 实例来加/减时延，来获得一个新的时间点，所 以 std::chrono::hight_resolution_clock::now() + std::chrono::nanoseconds(500) 将得到500纳 秒后的时间。

也可以减去一个时间点(二者需要共享同一个时钟)。结果是两个时间点的时间差。这对于代 码块的计时是很有用的，例如：

```c++
auto start=std::chrono::high_resolution_clock::now();
do_something();
auto stop=std::chrono::high_resolution_clock::now();
std::cout<<”do_something() took “<<std::chrono::duration<double,std::chrono::seconds>(stop-start).count()<<” seconds”<<std::endl;
```

清单4.11 等待一个条件变量——有超时功能

```c++
#include <condition_variable>
#include <mutex>
#include <chrono>
std::condition_variable cv;
bool done;
std::mutex m;
bool wait_loop()
{
    auto const timeout= std::chrono::steady_clock::now()+
    std::chrono::milliseconds(500);
    std::unique_lock<std::mutex> lk(m);
    while(!done)
    {
        if(cv.wait_until(lk,timeout)==std::cv_status::timeout)
        	break;
    }
    return done;
}

```

当没有什么可以等待时，就可在一定时限中等待条件变量。这种方式中， 循环的整体长度有限。

当使用条件变量(且无事可待)时，就需要使用循环， 这是为了处理假唤醒。

当在循环中使用wait_for()时，可能在等待了足够长的时间后结束等待 ((在假唤醒之前)，且下一次等待又开始了。这可能重复很多次，使得等待时间无边无际。

## 4.4 使用同步操作简化代码

同步工具的使用在本章称为构建块，你可以关注下那些需要同步的操作，而非使用具体的机 制

## 4.4.1 使用期望值的函数化编程

术语函数化编程(functional programming)引用于一种编程方式，这种方式中的函数结果**只依 赖于传入函数的参数，并不依赖外部状态。**

## 4.4.2 使用消息传递的同步操作

我们已经为你的ATM机逻辑设计了一个状态机，可以使用一个类实现它，这个类中有一个成 员函数可以代表每一个状态。每一个成员函数可以等待从指定集合中传入的信息，以及当它 们到达时进行处理，这就有可能触发原始状态向另一个状态的转化。每种不同的信息类型由 一个独立的struct表示。清单4.15展示了ATM逻辑部分的简单实现(以上描述的系统中，有主循 环和对第一状态的实现)，并且一直在等待卡片插入。 如你所见，所有信息传递所需的的同步，完全包含在“信息传递”库中(基本实现在附录C中，是 清单4.15代码的完整版)

```c++
struct card_inserted
{
	std::string account;
};
class atm
{
    messaging::receiver incoming;
    messaging::sender bank;
    messaging::sender interface_hardware;
    void (atm::*state)();
    std::string account;
    std::string pin;
    void waiting_for_card() // 1
    {
        interface_hardware.send(display_enter_card()); // 2
        incoming.wait(). // 3
        handle<card_inserted>([&](card_inserted const& msg) // 4
        {
            account=msg.account;
            pin="";
            interface_hardware.send(display_enter_pin());
            state=&atm::getting_pin;
        });
	}
void getting_pin();
public:
    void run() // 5
    {
        state=&atm::waiting_for_card; // 6
        try
        {
        	for(;;)
            {
            	(this->*state)(); // 7 第一次调用时是waiting_for_card 第二次调用是getting_pin
            }
         }
         catch(messaging::close_queue const&)
         {
         }
    }
};
```

运行从run()成员函数开始⑤，初始化waiting_for_card⑥的状态

然后反复执行当前状态的成 员函数(无论这个状态时怎么样的)⑦

状态函数是简易atm类的成员函数。wait_for_card函数 ①依旧很简单：它发送一条信息到接口，让终端显示“等待卡片”的信息②

之后就等待传入一 条消息进行处理③

处理的消息类型只能是card_inserted类的，这里使用一个Lambda函数④ 对其进行处理。

注意，handle()函数调用与wait()函数进行连接的； 当收到的信息类型与处理类型不匹配，收到的信息将会被丢弃，并且线程继续等待，直到接 收到一条类型匹配的消息。

Lambda函数自身只是将用户的账号信息缓存到一个成员变量中去，并且清除PIN信息，再发 送一条消息到硬件接口，让显示界面提示用户输入PIN，然后将线程状态改为“获取PIN”。当 消息处理程序结束，状态函数就会返回，然后主循环会调用新的状态函数⑦。

getting_pin状态函数会负载一些，因为其要处理三个不同的信息类型。具体代码展 示如下：

```c++
void atm::getting_pin()
{
    incoming.wait().handle<digit_pressed>( // 1
    [&](digit_pressed const& msg)
    {
        unsigned const pin_length=4;
        pin+=msg.digit;
        if(pin.length()==pin_length)
        {
            bank.send(verify_pin(account,pin,incoming));
            state=&atm::verifying_pin;
        }
    }).handle<clear_last_pressed>( // 2
    [&](clear_last_pressed const& msg)
    {
        if(!pin.empty())
        {
            pin.resize(pin.length()-1);
        }
    }).handle<cancel_pressed>( // 3
        [&](cancel_pressed const& msg)
        {
            state=&atm::done_processing;
        });
}

```

这次需要处理三种消息类型，所以wait()函数后面接了三个handle()函数调用①②③。每个 handle()都有对应的消息类型作为模板参数，并且将消息传入一个Lambda函数中(其获取消息 类型作为一个参数)。

因为调用都被连接在了一起，wait()的实现知道它是等待一条 digit_pressed消息，或是一条clear_last_pressed肖息，亦或是一条cancel_pressed消息，这 样其他的消息类型将会被丢弃。

当获取一条消息时，无需再去改变状态。比如，当获取一条digit_pressed消息时，仅需要将 其添加到pin中，除非那些数字是最终的输入。(清单4.15中)主循环⑦将会再次调用 getting_pin()去等待下一个数字(或清除数字，或取消交易)。

这里对应的动作如图4.3所示，每个状态盒的实现都由一个不同的成员函数构成，等待相关信 息并适当的更新状态。 一个并发系统中，这种编程方式可以极大的简化任务的设计，因为每一个线程都完全被独立 对待。因此，使用多线程去分离关注点时，需要明确线程之间的任务应该如何分配。

## 4.4.3 并发技术扩展规范中的持续性并发

并发技术扩展规范在 std::experiment 命名空间中提供了新 的 std::promise 和 std::packaged_taks 。与 std 命名空间中类型完全不同，其返回实例类型 为 std::experimental::future ，而不是 std::future 。这能让使用者体 会 std::experimental::future 所带来的新特性——持续性。

假设你的任务运行会产生一个结果，并且期望值持有这个结果。然后，需要写一些代码来处 理这个结果。使用 std::future 时，必须等待期望值状态变为就绪态，要不就使用全阻塞成员 函数wait()，或是使用wait_for()/wait_unitl()成员函数直到等待超时。这会让代码变得非常复 杂。想要用一句话来说，就是“完事俱备，只等数据”，这也就是持续性的意义。为了给期望值 添加持续性，只需要在成员函数后添加then()即可。比如：给定一个期望值fut，添加持续性的 调用即为fut.then(continuation)。

与 std::future 类似 , std::experimental::future 存储值也只能检索一次。如果期望值正处于 持续使用状态，那这个期望值就不能被其他代码所访问。因此，使用fut.then()为fut期望值添 加持续性后，对原始期望值fut的操作就是非法的。另外，调用fut.then()会返回一个新期望 值，这个新期望值会持有持续性调用的结果。具体代码，如下所示：

```c++
std::experimental::future<int> find_the_answer;
auto fut=find_the_answer();
auto fut2=fut.then(find_the_question);
assert(!fut.valid());
assert(fut2.valid());
```

## 4.4.4 持续性连接

假设你有一些列耗费时间的任务要完成，并且想要使用多线程的方式异步完成这些任务，从 而减轻主线程上的计算压力。例如：有用户登录了你的应用时，需要将登录凭证发送给后 台；然后，对身份信息进行验证后，进一步从后台获取用户的账户信息；最后，当索引到相 关信息后，使用获取到的信息对显示进行更新。串行执行的话，可以写成如下的方式： 清单4.18 处理用户登录——串行函数

```c++
void process_login(std::string const& username, std::string const& password)
{
    try{
        user_id const id = backend.authenticate_user(username,password);
        user_data const info_to_display =backend.request_current_info(id);
        update_display(info_to_display);
    } catch(std::exception& e){
    	display_error(e);
    }
}
```

不过，你不想要串行代码吧；你想要的是一段异步代码，所以不想阻塞UI线程。

使 用 std::async 将另一个列表全部放在后台线程上，不过这依旧会阻塞UI线程，在等待这些任 务完成的同时，会消耗大量的资源。如果有很多这样的任务，可以结束一些只在等待的线 程，从而节省资源。

```c++
std::future<void> process_login(std::string const& username, std::string const& password)
{
    return std::async(std::launch::async,[=](){
        try{
            user_id consst id = backend.authenticate_user(username,password);
            user_data const info_to_display =backend.request_current_info(id);
            update_display(info_to_display);
        } catch(std::exception& e){
        	display_error(e);
        }
    });
}
```

为了避免阻塞相应线程，需要有机制对每个完成的任务进行连接：持续性。下面的代码清单 展示的处理过程大体相同，但这次将整个任务分成了一系列任务，并且每个任务在完成的时 候回连接到前一个任务上。

```c++
std::experimental::future<void> process_login(
	std::string const& username, std::string const& password)
{
	return spawn_async([=](){
		return backend.authenticate_user(username, password);
	}).then([](std::experimental::future<user_id> id){
	return backend.request_current_info(id.get());
	}).then([](std::experimental::future<user_data>info_to_display){
        try{
            update_display(info_to_display.get());
        } catch(std::exception& e){
            display_error(e);
        }
    });
}
```

需要注意的是，每个持续性函数都有一个 std::experimental::future 作为独立参数，然后使 用 .get() 来获取其拥有的值。

这意味着异常会沿着这个链条进行传播，如果有函数抛出异 常，那么就会在调用info_to_display.get()时抛出，捕获结构可以处理所有的异常类型，就如清 单4.18的catch那样。

因为需要等待消息通过网络或数据操作进行传输，所函数内部会对后端模块进行调用，但这 时前端的任务可能还没有完成。虽然已经将任务进行分割成独立的小任务，但它们仍然会阻 塞调用，这样就会阻塞线程的运行，这些需要在后端任务完成时，前端处理就已经准备好 了，而不是对线程进行阻塞。这样的话， backend.async_authenticate_user(username,password)返 回 std::experimental::future 会比返回user_id更加合适。

你可能觉得这段代码比较复杂，因为持续函数返回的期望值类型 为 future> ，否则只能将调用 .then 的语句放置在持续函数中。如果这么 想，就错了；因为持续性支持一种极为精妙的特性，叫做期望值展开(future-unwrapping)。当 你向 .then() 传递了持续性函数，并且返回一个future类型的值时，相应的 .then() 的返回值 类型也是future。最终的代码可能如下所示，这样在异步函数链上就不会存在阻塞了。

清单4.21 处理用户登录——全异步操作

```c++
std::experimental::future<void> process_login(
std::string const& username, std::string const& password)
{
    return backend.async_authenticate_user(username,password).then(
    [](std::experimental::future<user_id> id){
    	return backend.async_request_current_info(id.get());
    }).then([](std::experimental::future<user_data>info_to_display){
        try{
        	update_display(info_to_display.get());
        } catch(std::exception& e){
        	display_error(e);
        }
    });
}
```

# 第5章 C++内存模型和原子类型操作

## 5.1 内存模型基础

## 5.1.1 对象和内存位置

一个C++程序中所有数据都是由对象构成。不是说创建一个int的衍生类，或者是基本类型中 存在有成员函数，或是像在Smalltalk和Ruby语言那样——“一切都是对象”。对象仅仅是对 C++数据构建块的声明。C++标准定义类对象为“存储区域”，但对象还是可以将自己的特性赋 予其他对象，比如：相应类型和生命周期。



## 5.2 C++中的原子操作和原子类型

原子操作是个不可分割的操作。系统的所有线程中，不可能观察到原子操作完成了一半；要 么就是做了，要么就是没做，只有这两种可能。

## 5.2.1 标准原子类型

标准原子类型定义在头文件atomic中。这些类型的所有操作都是原子的，语言定义中**只有 这些类型的操作**是原子的，不过可以用互斥锁来模拟原子操作。

实际上，标准原子类型的实 现就可能是这样模拟出来的：它们(几乎)都有一个 is_lock_free() 成员函数，这个函数可以让 用户查询某原子类型的操作是直接用的原子指令( x.is_lock_free() 返回 true )，还是内部用 了一个锁结构( x.is_lock_free() 返回 false )。

原子操作的关键就是使用一种同步操作方式，来替换使用互斥量的同步方式；如果操作内部 使用互斥量实现，那么期望达到的性能提升就是不可能的事情。所以要对原子操作进行实 现，最好使用用于获取且基于互斥量的实现来替代。这就是第7章所要讨论的无锁数据结构。

## 5.2.2 std::atomic_flag的相关操作

std::atomic_flag 是最简单的原子类型，它表示了一个布尔标志。这个类型的对象可以在两 个状态间切换：设置和清除。它将作为讨论其他原子类型的起点，因为它 会展示了原子类型所使用的通用策略。

std::atomic_flag 类型的对象必须被ATOMIC_FLAG_INIT初始化。初始化标志位是“清除”状 态。这里没得选择，这个标志总是初始化为“清除”：

```c++
std::atomic_flag f = ATOMIC_FLAG_INIT;
```

这适用于任何对象的声明，是唯一需要以如此特殊的方式初始化的原子类型，但也是唯一保 证无锁的类型。

如果 std::atomic_flag 是静态存储的，那么就的保证其是静态初始化的，也 就意味着没有初始化顺序问题；在首次使用时，其都需要初始化。

当标志对象已初始化，那么只能做三件事情：销毁，清除或设置(查询之前的值)。这些操作对 应的函数分别是：clear()成员函数和test_and_set()成员函数。

清单5.1 使用 std::atomic_flag 实现自旋互斥锁

```c++
class spinlock_mutex
{
	std::atomic_flag flag;
public:
    spinlock_mutex():
    flag(ATOMIC_FLAG_INIT)
    {}
    void lock()
    {
        while(flag.test_and_set(std::memory_order_acquire));
    }
    void unlock()
    {
        flag.clear(std::memory_order_release);
    }
};
```

这样的互斥量是最基本的，但它已经足够 std::lock_guard<> 使用了。当看到内存序语义时， 会了解到它们是如何对一个互斥锁保证必要的强制顺序的。这个例子将在5.3.6节中展示。

由于 std::atomic_flag 局限性太强，没有非修改查询操作，甚至不能像普通的布尔标志那样 使用。所以，实际中最好使用 std::atomic ，接下来让我们看看应该如何使用它。

## 5.2.3 std::atomic 的相关操作

最基本的原子整型类型就是 std::atomic 。如你所料，它有着比 std::atomic_flag 更加 齐全的布尔标志特性。虽然依旧不能拷贝构造和拷贝赋值，但可以使用非原子的bool类型进行 构造，所以可以被初始化为true或false，并且可以从非原子bool变量赋值 给 std::atomic ：

```c++
std::atomic<bool> b(true);
b=false;
```

虽然有内存序语义指定，但是使用store()去写入(true或false)还是好于 std::atomic_flag 中限 制性很强的clear()。同样，test_and_set()函数也可以被更加通用的exchange()成员函数所替 换，exchange()成员函数允许使用新选的值替换已存储的值，并且会自动检索原始 值。

。 std::atomic 也支持对值的不可修改)查找，其会将对象隐式的转换为一个普通的 bool值，或显示的调用load()来完成。如你预期，store()是一个存储操作，而load()是一个加载 操作。exchange()是一个“读-改-写”操作：

```c++
std::atomic<bool> b;
bool x=b.load(std::memory_order_acquire);
b.store(true);
x=b.exchange(false, std::memory_order_acq_rel);
```

std::atomic 提供的exchange()，不仅仅是一个“读-改-写”的操作；它还介绍了一种新的 存储方式：当当前值与预期值一致时，存储新值的操作。

存储一个新值(或旧值)取决于当前值

这种新型操作叫做“比较/交换”，它的形式表现为compare_exchange_weak()和 compare_exchange_strong()成员函数。

“比较/交换”函数值是一个bool变量，当返回true时执行存储操作， false则更新期望值。当存储完成(因为只相等)，则操作时成功的，否则即为失败；操作成功是 返回true，失败时返回false。

对于compare_exchange_weak()函数，当原始值与预期值一致时，存储也可能会不成功；在 这个例子中变量的值不会发生改变，并且compare_exchange_weak()的返回是false。这可能 发生在缺少单条CAS操作(“比较-交换”指令)的机器上，当处理器不能保证这个操作能够自动的 完成——可能因为线程的操作将指令队列从中间关闭，并且另一个线程安排的指令将会被操 作系统所替换(这里线程数多于处理器数量)，被称为“伪失败”(spurious failure)，因为造成这种 情况的原因是时间，而不是变量值。

因为compare_exchange_weak()可以伪失败，所以通常使用一个循环：

```c++
bool expected=false;
extern atomic<bool> b; // 设置些什么
while(!b.compare_exchange_weak(expected,true) && !expected);
```

这个例子中，循环中expected的值始终是false，表示compare_exchange_weak()会莫名的失 败。

另一方面，当实际值与期望值不符，compare_exchange_strong()就能保证值返回false。这就 能消除对循环的需要，就可以知道是否成功的改变了一个变量，或已让另一个线程完成。

经历每次循环的时候，期望值都会重 新加载，所以当没有其他线程同时修改期望时，循环中对compare_exchange_weak()或 compare_exchange_strong()的调用都会在下一次(第二次)成功。如果值很容易存储，那么使 用compare_exchange_weak()能更好的避免一个双重循环的执行，即使 compare_exchange_weak()可能会“伪失败”(因此compare_exchange_strong()包含一个循 环)。

另一方面，如果值的存储本身是耗时的，那么当期望值不变时，使用 compare_exchange_strong()可以避免对值的重复计算。

## 5.2.4 std::atomic :指针运算

原子指针类型，可以使用内置类型或自定义类型T，通过特化 std::atomic 进行定义

如 同使用bool类型定义 std::atomic 类型一样。虽然接口几乎一致，但是它的操作是对于 相关的类型的指针，而非bool值

。就像 std::atomic ，虽然既不能拷贝构造，也不能拷 贝赋值，但是可以通过合适的类型指针进行构造和赋值。

。如同成员函数is_lock_free()一 样， std::atomic 也有load(), store(), exchange(), compare_exchange_weak()和 compare_exchage_strong()成员函数，与 std::atomic 的语义相同，获取与返回的类型 都是T*，而不是bool。

std::atomic 为指针运算提供新的操作。基本操作有fetch_add()和fetch_sub()提供，它们 在存储地址上做原子加法和减法，为+=, -=, ++和--提供简易的封装。

对于内置类型的操作， 例如：如果x是 std::atomic 类型的数组的首地址，然后x+=3让其偏移到第四个元素的 地址，并且返回一个普通的 Foo* 类型值，这个指针值是指向数组中第四个元素。fetch_add() 和fetch_sub()的返回值略有不同x.ftech_add(3)让x指向第四个元素，并且函数返回指向 第一个元素的地址

这种操作也被称为“交换-相加”，并且这是一个原子的“读-改-写”操作，如 同exchange()和compare_exchange_weak()/compare_exchange_strong()一样

正像其他操 作那样，返回值是一个普通的 T* 值，而非是 std::atomic 对象的引用，所以调用代码可 以基于之前的值进行操作：

```c++
class Foo{};
Foo some_array[5];
std::atomic<Foo*> p(some_array);
Foo* x=p.fetch_add(2); // p加2，并返回原始值
assert(x==some_array);
assert(p.load()==&some_array[2]);
x=(p-=1); // p减1，并返回原始值
assert(x==&some_array[1]);
assert(p.load()==&some_array[1]);
```

## 5.2.6 std::atomic<> 类模板

模板的存在，除了标准原子类型之外，允许用户使用自定义类型创建一个原子变量。不是任 何自定义类型都可以使用 std::atomic<> 的：需要满足一定的标准才行。

用 std::atomic (UDT是用户定义类型)，这个类型必须有**拷贝赋值运算符**。

这就意味着这 个类型不能有任何虚函数或虚基类，以及必须使用编译器创建的拷贝赋值操作。

不仅仅是这 些，自定义类型中所有的基类和非静态数据成员也都需要支持拷贝赋值操作。这(基本上)就允 许编译器使用memcpy()或赋值操作的等价操作，因为实现中没有用户代码。

以上严格的限制都是依据第3章中的一个建议：不要将锁定区域内的数据以引用或指针的形 式，作为参数传递给用户提供的函数。

通常情况下，编译器不会为 std::atomic 类型生 成无锁代码，所以所有操作使用一个内部锁。

当使用用户定义类型T进行实例化时， std::atomic 的可用接口就只有: load(), store(), exchange(), compare_exchange_weak(), compare_exchange_strong()和赋值操作，以及向 类型T转换的操作。

## 5.2.7 原子操作的释放函数

## 5.3 同步操作和强制排序

假设两个线程，一个向数据结构中填充数据，另一个读取数据结构中的数据。为了避免恶性 条件竞争，第一个线程设置一个标志，用来表明数据已经准备就绪，并且第二个线程在这个 标志设置前不能读取数据。下面的程序清单就是这样的情况：

```c++
#include <vector>
#include <atomic>
#include <iostream>
std::vector<int> data;
std::atomic<bool> data_ready(false);
void reader_thread()
{
    while(!data_ready.load()) // 1
    {
    	std::this_thread::sleep(std::milliseconds(1));
    }
    std::cout<<"The answer="<<data[0]<<"\m"; // 2
}
void writer_thread()
{
    data.push_back(42); // 3
    data_ready=true; // 4
}
```

先把等待数据的循环①放在一边(你需要这个循环，否则无法在线程间进行数据共享：每一个 数据项都必须是原子的)。

当非原子读②和写③对同一数据结构进行无序访问时，将会导致未 定义行为的发生，因此这个循环就是确保访问循序被严格的遵守的。

# 第6章 基于锁的并发数据结构设计

## 6.2.1 线程安全栈——使用锁

```c++
#include <exception>
struct empty_stack: std::exception
{
    const char* what() const throw();
};
template<typename T>
class threadsafe_stack
{
private:
    std::stack<T> data;
    mutable std::mutex m;
public:
    threadsafe_stack(){}
    threadsafe_stack(const threadsafe_stack& other)
    {
        std::lock_guard<std::mutex> lock(other.m);
        
        data=other.data;
    }
    threadsafe_stack& operator=(const threadsafe_stack&) = delete;
    void push(T new_value)
    {
        std::lock_guard<std::mutex> lock(m);
        data.push(std::move(new_value)); // 1
    }
    std::shared_ptr<T> pop()
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack(); // 2
        std::shared_ptr<T> const res(
        std::make_shared<T>(std::move(data.top()))); // 3
        data.pop(); // 4
        return res;
    }
    void pop(T& value)
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack();
        value=std::move(data.top()); // 5
        data.pop(); // 6
    }
    bool empty() const
    {
        std::lock_guard<std::mutex> lock(m);
        return data.empty();
    }
};

```

## 6.2.2 线程安全队列——使用锁和条件变量

```c++
template<typename T>
class threadsafe_queue
{
private:
    mutable std::mutex mut;
    std::queue<T> data_queue;
    std::condition_variable data_cond;
public:
    threadsafe_queue()
    {}
    void push(T new_value)
    {
        std::lock_guard<std::mutex> lk(mut);
        data_queue.push(std::move(data));
        data_cond.notify_one(); // 1
    }
    void wait_and_pop(T& value) // 2
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk,[this]{return !data_queue.empty();});
        value=std::move(data_queue.front());
        data_queue.pop();
    }
    std::shared_ptr<T> wait_and_pop() // 3
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk,[this]{return !data_queue.empty();}); //4
        std::shared_ptr<T> res(
        std::make_shared<T>(std::move(data_queue.front())));
        data_queue.pop();
        return res;
    }
    bool try_pop(T& value)
    {
        std::lock_guard<std::mutex> lk(mut);
        if(data_queue.empty())
        return false;
        value=std::move(data_queue.front());
        data_queue.pop();
        return true;
    }
    std::shared_ptr<T> try_pop()
    {
        std::lock_guard<std::mutex> lk(mut);
        if(data_queue.empty())
        return std::shared_ptr<T>(); // 5
        std::shared_ptr<T> res(
        std::make_shared<T>(std::move(data_queue.front())));
        data_queue.pop();
        return res;
    }
    bool empty() const
    {
        std::lock_guard<std::mutex> lk(mut);
        return data_queue.empty();
    }
};
```

## 6.2.3 线程安全队列——使用细粒度锁和条件变量

```c++
template<typename T>
class queue
{
private:
    struct node
    {
        T data;
        std::unique_ptr<node> next;
        node(T data_):data(std::move(data_)){}
	};
    std::unique_ptr<node> head; // 1
    node* tail; // 2
public:
    queue(){}
    queue(const queue& other)=delete;
    queue& operator=(const queue& other)=delete;
    std::shared_ptr<T> try_pop()
    {
        if(!head)
        {
        	return std::shared_ptr<T>();
        }
        std::shared_ptr<T> const res(std::make_shared<T>(std::move(head->data)));
        std::unique_ptr<node> const old_head=std::move(head);
        head=std::move(old_head->next); // 3
        return res;
    }
    void push(T new_value)
    {
        std::unique_ptr<node> p(new node(std::move(new_value)));
        node* const new_tail=p.get();
        if(tail)
        {
        	tail->next=std::move(p); // 4
        }
        else
        {
        	head=std::move(p); // 5
        }
        tail=new_tail; // 6
    }
};
```

使用了 std::unique_ptr 来管理节点，因为其能保证节点(其引用 数据的值)在删除时候，不需要使用delete操作显式删除。

在给定的实现中有两个数据项(head①和tail②)；即使，使用两个互斥量来保护 头指针和尾指针，也会出现问题。

push()可以同时修改头指针⑤和尾指针⑥，所以push()函数会同时获取两个 互斥量。虽然会将两个互斥量都上锁，但这问题还不算太糟糕。糟糕的是push()和pop()都能 访问next指针指向的节点：push()可更新tail->next④，随后try_pop()读取read->next③。当队列中只有一个元素时，head==tail，所以head->next和tail->next是同一个对象，并且这个对象 需要保护。不过，“在同一个对象在未被head和tail同时访问时，push()和try_pop()锁住的是同 一个锁”就不对了。

通过分离数据实现并发

可以使用“预分配一个虚拟节点(无数据)，确保这个节点永远在队列的最后，用来分离头尾指 针能访问的节点”的办法，走出这个困境。对于一个空队列来说，head和tail都属于虚拟指针， 而非空指针。这个办法挺好，因为当队列为空时，try_pop()不能访问head->next了。当添加 一个节点入队列时(这时有真实节点了)，head和tail现在指向不同的节点，所以就不会在head- >next和tail->next上产生竞争。这里的缺点是，必须额外添加一个间接层次的指针数据，来做 虚拟节点。下面的代码描述了这个方案如何实现。

## 带有虚拟节点的队列

```c++
template<typename T>
class queue
{
private:
    struct node
    {
        std::shared_ptr<T> data; // 1
        std::unique_ptr<node> next;
    };
    std::unique_ptr<node> head;
    node* tail;
public:
    queue():
    head(new node),tail(head.get()) // 2
    {}
    queue(const queue& other)=delete;
    queue& operator=(const queue& other)=delete;
    std::shared_ptr<T> try_pop()
    {
        if(head.get()==tail) // 3
        {
            return std::shared_ptr<T>();
        }
        std::shared_ptr<T> const res(head->data); // 4
        std::unique_ptr<node> old_head=std::move(head);
        head=std::move(old_head->next); // 5
        return res; // 6
    }
    void push(T new_value)
    {
        std::shared_ptr<T> new_data(
        std::make_shared<T>(std::move(new_value))); // 7
        std::unique_ptr<node> p(new node); //8
        tail->data=new_data; // 9
        node* const new_tail=p.get();
        tail->next=std::move(p);
        tail=new_tail;
    }
};

```

## 线程安全队列——细粒度锁版

```c++
template<typename T>
class threadsafe_queue
{
private:
    struct node
    {
        std::shared_ptr<T> data;
        std::unique_ptr<node> next;
    };
    std::mutex head_mutex;
    std::unique_ptr<node> head;
    std::mutex tail_mutex;
    node* tail;
    node* get_tail()
    {
        std::lock_guard<std::mutex> tail_lock(tail_mutex);
        return tail;
    }
    std::unique_ptr<node> pop_head()
    {
        std::lock_guard<std::mutex> head_lock(head_mutex);
        if(head.get()==get_tail())
        {
            return nullptr;
        }
        std::unique_ptr<node> old_head=std::move(head);
        head=std::move(old_head->next);
        return old_head;
    }
public:
    threadsafe_queue():
    head(new node),tail(head.get())
    {}
    threadsafe_queue(const threadsafe_queue& other)=delete;
    threadsafe_queue& operator=(const threadsafe_queue&
    other)=delete;
    std::shared_ptr<T> try_pop()
    {
        std::unique_ptr<node> old_head=pop_head();
        return old_head?old_head->data:std::shared_ptr<T>();
    }
    void push(T new_value)
    {
        std::shared_ptr<T> new_data(
        std::make_shared<T>(std::move(new_value)));
        std::unique_ptr<node> p(new node);
        node* const new_tail=p.get();
        std::lock_guard<std::mutex> tail_lock(tail_mutex);
        tail->data=new_data;
        tail->next=std::move(p);
        tail=new_tail;
    }
};

```

## 可上锁和等待的线程安全队列——wait_and_pop()

```c++
template<typename T>
class threadsafe_queue
{
private:
    node* get_tail()
    {
        std::lock_guard<std::mutex> tail_lock(tail_mutex);
        return tail;
    }
    std::unique_ptr<node> pop_head() // 1
    {
        std::unique_ptr<node> old_head=std::move(head);
        head=std::move(old_head->next);
        return old_head;
    }
    std::unique_lock<std::mutex> wait_for_data() // 2
    {
        std::unique_lock<std::mutex> head_lock(head_mutex);
        data_cond.wait(head_lock,[&]{return
        head.get()!=get_tail();});
        return std::move(head_lock); // 3
    }
    std::unique_ptr<node> wait_pop_head()
    {
        std::unique_lock<std::mutex> head_lock(wait_for_data()); //4
        return pop_head();
    }
    std::unique_ptr<node> wait_pop_head(T& value)
    {
        std::unique_lock<std::mutex> head_lock(wait_for_data()); //5
        value=std::move(*head->data);
        return pop_head();
    }
public:
    std::shared_ptr<T> wait_and_pop()
    {
        std::unique_ptr<node> const old_head=wait_pop_head();
        return old_head->data;
    }
    void wait_and_pop(T& value)
    {
        std::unique_ptr<node> const old_head=wait_pop_head(value);
    }
};
```

## 可上锁和等待的线程安全队列——try_pop()和empty()

```c++
template<typename T>
class threadsafe_queue
{
private:
    std::unique_ptr<node> try_pop_head()
    {
        std::lock_guard<std::mutex> head_lock(head_mutex);
        if(head.get()==get_tail())
        {
        	return std::unique_ptr<node>();
    	}
    	return pop_head();
    }
    std::unique_ptr<node> try_pop_head(T& value)
    {
        std::lock_guard<std::mutex> head_lock(head_mutex);
        if(head.get()==get_tail())
        {
        	return std::unique_ptr<node>();
        }
        value=std::move(*head->data);
        return pop_head();
    }
public:
    std::shared_ptr<T> try_pop()
    {
        std::unique_ptr<node> old_head=try_pop_head();
        return old_head?old_head->data:std::shared_ptr<T>();
    }
    bool try_pop(T& value)
    {
        std::unique_ptr<node> const old_head=try_pop_head(value);
        return old_head;
    }
    bool empty()
    {
        std::lock_guard<std::mutex> head_lock(head_mutex);
        return (head.get()==get_tail());
    }
};
```

# 第7章 无锁并发数据结构设计

## 使用 std::atomic_flag 实现了一个简单的自旋锁

```c++
class spinlock_mutex
{
	std::atomic_flag flag;
public:
    spinlock_mutex():
    flag(ATOMIC_FLAG_INIT)
    {}
    void lock()
    {
        while(flag.test_and_set(std::memory_order_acquire));
    }
    void unlock()
    {
        flag.clear(std::memory_order_release);
    }
};
```

## 实现一个无锁的线程安全栈

不用锁实现push

```c++
template<typename T>
class lock_free_stack
{
private:
    struct node
    {
        T data;
        node* next;
        node(T const& data_): // 1
        data(data_)
        {}
    };
    std::atomic<node*> head;
public:
    void push(T const& data)
    {
        node* const new_node=new node(data); // 2
        new_node->next=head.load(); // 3
        while(!head.compare_exchange_weak(new_node->next,new_node));// 4
    }
};
```

pop

```c++
template<typename T>
class lock_free_stack
{
public:
    void pop(T& result)
    {
        node* old_head=head.load();
        while(!head.compare_exchange_weak(old_head,old_head->next));
        result=old_head->data;
    }
};
```



# 线程池

```c++
class thread_pool
{
    std::atomic_bool done;
    thread_safe_queue<std::function<void()> > work_queue; // 1
    std::vector<std::thread> threads; // 2
    join_threads joiner; // 3
    void worker_thread()
    {
        while(!done) // 4
        {
            std::function<void()> task;
            if(work_queue.try_pop(task)) // 5
            {
                task(); // 6
            }
            else
            {
                std::this_thread::yield(); // 7
            }
        }
    }
public:
    thread_pool():done(false),joiner(threads)
    {
        unsigned const
        thread_count=std::thread::hardware_concurrency(); // 8
        try
        {
        	for(unsigned i=0;i<thread_count;++i)
        	{
                threads.push_back(
                std::thread(&thread_pool::worker_thread,this)); // 9
    		}
    	}
   		catch(...)
        {
            done=true; // 10
            throw;
        }
    }
    ~thread_pool()
    {
    	done=true; // 11
    }
    template<typename FunctionType>
    void submit(FunctionType f)
    {
    	work_queue.push(std::function<void()>(f)); // 12
    }
};
```

实现中有一组工作线程②，并且使用线程安全队列(见第6章)①来管理任务队列。这种情况 下，用户不用等待任务，并且任务不需要返回任何值，所以可以使 用 std::function 对任务进行封装。submit()会将函数或可调用对象包装成一 个 std::function 实例，并将其推入队列中⑫。

# 屏障

