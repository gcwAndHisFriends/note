# FaRM与乐观锁并发控制

与spanner相比，farm很像。

但faRM假设所有replica在同一个数据中心，容错能力不能保护整个数据中心。其选用了RDMA这个技术。

FaRM强制使用乐观锁并发控制，性能高于Spanner100倍。瓶颈位于服务器上的cpu时间

数据中心有一个配置管理器(master)决定哪台服务器是primary，哪那个是backup。用zookeeper实现

FaRM根据key将数据进行分片并分散到一堆primary-backup pair上。当有一处发生改变，该数据所属所有replica都会更新

可以将协调器看作独立的client

每个client除了执行事务，还扮演两阶段提交中事务协调器的角色

数据分片:将数据分割到90个机器上，以获得更高性能

将数据放在服务器的RAM中(非易失NVRAM)

RDMA技术:不对服务器发出中断信号的情况下，通过网络接口卡(NIC)接收数据包并通过指令直接对服务器内存中数据读写(kernel bypass)

# 非易失RAM

为了防止区域停电，可以用电池。在电池持续时间，将数据复制到磁盘

# 挑战:需要通过CPU时间来处理网络交互

传统架构不同服务器上程序的RPC数据包的交换:A发一条RPC，应用程序在用户态空间运行，为了发送数据，

1:应用程序调用内核系统调用

2:在socket层中，socket对数据进行缓存

3:然后再TCP协议栈，实现重传，序列化，checksum和flow control 

4:通过网络接口卡(NIC)的硬件，将数据发送



# 网络传输解决方法

## kernel bypass

通过对内核保护机制进行配置，让应用程序直接访问网路接口卡。通过DMA，NIC能直接访问应用程序内存(不需要内核参与)。kernel by pass可以用DPDK的工具包实现

## RDMA

(one-sided RDMA)远程内存直接访问，需要一种特殊网络接口卡才能支持。

源机可以通过RDMA系统发一条特殊的消息告诉网络接口卡，让源机直接对目标程序地址空间中内存进行读写

瓶颈:无法实现上锁之类的任务

# 乐观锁并发控制

可以在没锁(任何时候)读数据

不会直接写入数据，而是将写操作缓存在client本地，直到事务结束。当最终结束时，再试着提交数据。

会有一个**验证阶段**，事务处理系统会尝试搞清楚读写操作是否执行顺序一致。判断当我读数据时，是否有人在写它。

如果验证成功，提交。

如果验证失败，重新执行。

# 如何检测:

Farm是一个API式程序

```
o=txRead(oid)
o.f+=1
txWrite(oid,o)
ok=txCommit()
```

当失败时，会有指数补偿(增加时延)

当调用txRead时，会读取相关服务器上数据，txWrite只会对本地buffer数据修改，commit时才会提交事务

oid第一部分标识存储区域编号，第二部分标识该区域中的内存地址，client从当前primary和backup中的表查找。

服务器内存布局:服务器会把一个或多个区域的数据复制到内存中(每个区域都是一个集合对象)每个对象内部有一个header,包含了版本号，每个对象只有一个版本号。header中高位有一个lock标志位，地位存放数据的版本号。之后就是实际数据。

当对一个对象(集合对象)进行修改，就会对其版本号+1

服务器内存中还有许多对消息队列，该系统其他服务器里，每个服务器都有一份log日志，日志通过RDMA进行追加。所以一共有n^2个队列(一台服务器与另一台服务器建立的channel中有一个读队列，一个写队列)

写操作修改时，会检查是否有lock标记，并检查版本号，失败返回no，成功则返回yes并上锁





